{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyun/venv/torch_venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.0.9:5000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sent successfully for person 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/hyun/venv/torch_venv/lib/python3.12/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Error sending data: HTTPConnectionPool(host='192.168.0.8', port=8000): Read timed out. (read timeout=1)\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n",
      "Data sent successfully for person 0\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, jsonify\n",
    "import threading\n",
    "import requests\n",
    "import time\n",
    "import cv2\n",
    "from collections import defaultdict, deque\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import torch.nn as nn\n",
    "\n",
    "# Flask 서버 설정\n",
    "app = Flask(__name__)\n",
    "MAIN_SERVER_URL = \"http://192.168.0.8:8000/api/receive\"\n",
    "\n",
    "# YOLO 모델 로드 (더 가벼운 모델 고려)\n",
    "pose_model = YOLO(\"yolov8n-pose.pt\")  \n",
    "object_model = YOLO(\"yolov8n.pt\")  \n",
    "\n",
    "# 학습된 클래스 이름\n",
    "class_names = [\"running\", \"walking\", \"sitting\", \"lying\"]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LSTMPoseClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.5):\n",
    "        super(LSTMPoseClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "        hidden = hidden[-1]\n",
    "        return self.fc(hidden)\n",
    "\n",
    "# LSTM 모델 로드\n",
    "lstm_model = LSTMPoseClassifier(input_dim=17 * 2, hidden_dim=128, output_dim=len(class_names)).to(device)\n",
    "lstm_model.load_state_dict(torch.load(\"lstm_pose_classifier2.0.pth\", map_location=device))\n",
    "lstm_model.eval()\n",
    "\n",
    "class TargetDetector:\n",
    "    def __init__(self):\n",
    "        self.last_transmission_time = 0\n",
    "        self.transmission_interval = 2  # 2초마다 전송\n",
    "        self.sequence_buffers = defaultdict(lambda: deque(maxlen=96))\n",
    "\n",
    "    def send_data_to_server(self, person_id, pose_box, predicted_class, confidence, detected_class):\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_transmission_time < self.transmission_interval:\n",
    "            return\n",
    "\n",
    "        data = {\n",
    "            \"person_id\": person_id,\n",
    "            \"pose_box\": pose_box.tolist(),\n",
    "            \"predicted_class\": predicted_class,\n",
    "            \"confidence\": float(confidence) if confidence is not None else 0,\n",
    "            \"detected_class\": detected_class\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(MAIN_SERVER_URL, json=data, timeout=1)\n",
    "            if response.status_code == 200:\n",
    "                self.last_transmission_time = current_time\n",
    "                print(f\"Data sent successfully for person {person_id}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error sending data: {e}\")\n",
    "\n",
    "def extract_landmarks_and_boxes(frame, model):\n",
    "    \"\"\"\n",
    "    YOLO Pose 모델로 랜드마크와 바운딩 박스 추출\n",
    "    Args:\n",
    "        frame (np.array): 프레임 이미지\n",
    "        model: YOLO Pose 모델\n",
    "    Returns:\n",
    "        list: 각 사람의 [(person_id, landmarks, box)]\n",
    "    \"\"\"\n",
    "    results = model(frame, verbose=False)\n",
    "    height, width, _ = frame.shape\n",
    "    people_data = []\n",
    "\n",
    "    if len(results) > 0 and hasattr(results[0], 'keypoints'):\n",
    "        keypoints = results[0].keypoints.xy.cpu().numpy()  # (N, 17, 2)\n",
    "        boxes = results[0].boxes.xyxy.cpu().numpy()  # (N, 4)\n",
    "        for person_id, (landmarks, box) in enumerate(zip(keypoints, boxes)):\n",
    "            # 좌표를 프레임 크기로 정규화\n",
    "            keypoints_normalized = landmarks / [width, height]\n",
    "            people_data.append((person_id, keypoints_normalized, box))\n",
    "    return people_data\n",
    "\n",
    "def predict_class(sequence, model):\n",
    "    \"\"\"\n",
    "    LSTM 모델로 클래스 예측\n",
    "    Args:\n",
    "        sequence (deque): 랜드마크 시퀀스\n",
    "        model (nn.Module): 학습된 LSTM 모델\n",
    "    Returns:\n",
    "        str: 예측된 클래스 이름\n",
    "    \"\"\"\n",
    "    if len(sequence) < 96:\n",
    "        return \"Waiting for data...\"\n",
    "\n",
    "    input_tensor = torch.tensor(np.array(sequence), dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    input_tensor = input_tensor.view(input_tensor.size(0), input_tensor.size(1), -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return class_names[predicted.item()]\n",
    "\n",
    "@app.route(\"/classification\", methods=[\"GET\"])\n",
    "def send_data():\n",
    "    detector = TargetDetector()\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)   # 낮은 해상도\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)  # 낮은 해상도\n",
    "    frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % 2 != 0:  # 프레임 스키핑\n",
    "            continue\n",
    "\n",
    "        # YOLO Pose로 랜드마크와 박스 추출\n",
    "        people_data = extract_landmarks_and_boxes(frame, pose_model)\n",
    "\n",
    "        for person_id, landmarks, pose_box in people_data:\n",
    "            detector.sequence_buffers[person_id].append(landmarks)\n",
    "            predicted_class = predict_class(detector.sequence_buffers[person_id], lstm_model)\n",
    "\n",
    "            # 서버로 데이터 전송 (2초 간격)\n",
    "            detector.send_data_to_server(\n",
    "                person_id, \n",
    "                pose_box, \n",
    "                predicted_class, \n",
    "                None,  # 신뢰도 임시 제거 \n",
    "                \"person\"\n",
    "            )\n",
    "\n",
    "            # 시각화 코드 (선택적)\n",
    "            x1, y1, x2, y2 = map(int, pose_box)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(\n",
    "                frame,\n",
    "                f\"Pose: {predicted_class}\",\n",
    "                (x1, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7,\n",
    "                (255, 0, 0),\n",
    "                2,\n",
    "            )\n",
    "\n",
    "        cv2.imshow(\"Pose Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    thread = threading.Thread(target=send_data, daemon=True)\n",
    "    thread.start()\n",
    "    app.run(host=\"0.0.0.0\", port=5000, debug=False, threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
