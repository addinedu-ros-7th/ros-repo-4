import torch
import os
import numpy as np
import io
import cv2
from PIL import Image
from ts.torch_handler.base_handler import BaseHandler
from ultralytics import YOLO

class FireDetectionHandler(BaseHandler):
    def initialize(self, context):
        """ ğŸ”¥ ëª¨ë¸ ì´ˆê¸°í™” """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model_dir = context.system_properties.get("model_dir")
        model_path = os.path.join(model_dir, "fire.pt")

        # YOLOv8 ëª¨ë¸ ë¡œë“œ
        self.model = YOLO(model_path).to(self.device)
        self.model.eval()

        self.confidence_threshold = float(os.environ.get("CONFIDENCE_THRESHOLD", 0.4))

        print(f"âœ… Fire Detection Model (YOLOv8) Loaded Successfully with threshold {self.confidence_threshold}")

    def preprocess(self, data):
        """ ğŸ”¥ ì˜ìƒ ì „ì²˜ë¦¬ (ë™ì˜ìƒ â†’ í”„ë ˆì„) """
        try:
            video_bytes = data[0].get("body", None)
            if video_bytes is None:
                raise ValueError("âŒ Received empty video data")

            # OpenCVì—ì„œ ì½ì„ ìˆ˜ ìˆë„ë¡ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            video_path = "/tmp/fire_video.mp4"
            with open(video_path, "wb") as f:
                f.write(video_bytes)

            cap = cv2.VideoCapture(video_path)

            if not cap.isOpened():
                raise ValueError("âŒ VideoCapture failed to open video file")

            frames = []
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # ğŸš€ YOLOv8 ì…ë ¥ ì‚¬ì´ì¦ˆë¡œ ë¦¬ì‚¬ì´ì§• (32ì˜ ë°°ìˆ˜)
                target_size = (320, 256)  # YOLO ëª¨ë¸ì˜ ìµœì  ì…ë ¥ í¬ê¸°
                frame = cv2.resize(frame, target_size)
                frame = torch.from_numpy(frame).permute(2, 0, 1).float().to(self.device) / 255.0
                frames.append(frame)

            cap.release()

            if len(frames) == 0:
                raise ValueError("âŒ No valid frames found in video")

            print(f"ğŸ“Œ Total Frames Extracted: {len(frames)}")
            return {"frames": frames}
        
        except Exception as e:
            print(f"ğŸ”¥ Preprocessing error: {e}")
            return None

    def inference(self, data):
        """ ğŸ”¥ YOLOv8 ê¸°ë°˜ ë¶ˆ/ì—°ê¸° íƒì§€ """
        with torch.no_grad():
            results = [self.model(frame.unsqueeze(0), verbose=False)[0] for frame in data["frames"]]
        return results

    def postprocess(self, detections):
        """ ğŸ”¥ íƒì§€ëœ ê²°ê³¼ í›„ì²˜ë¦¬ (í”„ë ˆì„ë³„ íƒì§€ ì •ë³´) """
        predictions = []
        
        for result in detections:
            boxes = result.boxes.xyxy.cpu().numpy() if hasattr(result.boxes, 'xyxy') else []
            scores = result.boxes.conf.cpu().numpy() if hasattr(result.boxes, 'conf') else []
            classes = result.boxes.cls.cpu().numpy() if hasattr(result.boxes, 'cls') else []

            frame_predictions = []
            for i in range(len(boxes)):
                x_min, y_min, x_max, y_max = boxes[i]
                
                confidence = float(scores[i])

                # âœ… Confidence Threshold ì ìš© (ê¸°ë³¸ê°’: 0.5)
                if confidence < self.confidence_threshold:
                    continue


                class_mapping = {0: 100, 1: 101}  # 0: ë¶ˆ â†’ 100, 1: ì—°ê¸° â†’ 101
                adjusted_class_id = class_mapping.get(int(classes[i]), 199)

                frame_predictions.append({
                    "bbox": [float(x_min), float(y_min), float(x_max), float(y_max)],
                    "confidence": float(scores[i]),
                    "class_id": adjusted_class_id
                })

            # ğŸ”¥ íƒì§€ëœ ê°ì²´ê°€ ìˆëŠ” ê²½ìš°ë§Œ predictionsì— ì¶”ê°€
            if frame_predictions:
                predictions.append(frame_predictions)

        return predictions

    def handle(self, data, context):
        """ ğŸ”¥ ìš”ì²­ ì²˜ë¦¬ (ì „ì²˜ë¦¬ â†’ ì¶”ë¡  â†’ í›„ì²˜ë¦¬) """
        preprocessed_data = self.preprocess(data)
        if preprocessed_data is None:
            return [{"results": []}]  # âœ… ë¹ˆ ì‘ë‹µë„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ë°˜í™˜

        detections = self.inference(preprocessed_data)
        response = self.postprocess(detections)

        # ğŸ”¥ TorchServe í˜¸í™˜ ì‘ë‹µ ë°˜í™˜
        return [{"results": response}]  # âœ… ë°˜ë“œì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ë°˜í™˜
