import torch
import os
import numpy as np
import io
import cv2
from PIL import Image
from ts.torch_handler.base_handler import BaseHandler
from ultralytics import YOLO  # YOLOv8 ëª¨ë¸ ë¡œë“œ

class YOLOv8Handler(BaseHandler):
    def initialize(self, context):
        """ ëª¨ë¸ ì´ˆê¸°í™” """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model_dir = context.system_properties.get("model_dir")
        model_path = os.path.join(model_dir, "yolov8n.pt")

        # YOLOv8 ëª¨ë¸ ë¡œë“œ
        self.model = YOLO(model_path).to(self.device)
        self.model.eval()
        print("âœ… YOLOv8 Model loaded successfully")

    def preprocess(self, data):
        """ ì˜ìƒ ì „ì²˜ë¦¬ """
        try:
            video_bytes = data[0].get("body", None)
            if video_bytes is None:
                raise ValueError("âŒ Received empty video data")

            # OpenCVë¡œ ì½ì„ ìˆ˜ ìˆë„ë¡ íŒŒì¼ë¡œ ì €ì¥ í›„ ë‹¤ì‹œ ë¡œë“œ
            video_path = "/tmp/temp_video.mp4"
            with open(video_path, "wb") as f:
                f.write(video_bytes)

            cap = cv2.VideoCapture(video_path)

            if not cap.isOpened():
                raise ValueError("âŒ VideoCapture failed to open video file")

            frames = []
            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                # ğŸš€ YOLOv8ì´ í—ˆìš©í•˜ëŠ” í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì§• (Stride 32ì˜ ë°°ìˆ˜)
                target_size = (320, 256)  # 32ì˜ ë°°ìˆ˜ì¸ í¬ê¸°ë¡œ ì¡°ì •
                frame = cv2.resize(frame, target_size)
                frame = torch.from_numpy(frame).permute(2, 0, 1).float().to(self.device) / 255.0
                frames.append(frame)

            cap.release()

            if len(frames) == 0:
                raise ValueError("âŒ No valid frames found in video")

            print(f"ğŸ“Œ Total Frames Extracted: {len(frames)}")
            return {"frames": frames}
        
        except Exception as e:
            print(f"ğŸ”¥ Preprocessing error: {e}")
            return None

    def inference(self, data):
        """ YOLOv8 ëª¨ë¸ ì¶”ë¡  """
        with torch.no_grad():
            results = [self.model(frame.unsqueeze(0), verbose=False)[0] for frame in data["frames"]]
        return results

    def postprocess(self, data):
        """ YOLOv8 ê²°ê³¼ í›„ì²˜ë¦¬ (ì—¬ëŸ¬ í”„ë ˆì„ ì§€ì›) """
        predictions = []
        for result in data:
            boxes = result.boxes.xyxy.cpu().numpy()  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
            scores = result.boxes.conf.cpu().numpy()  # ì‹ ë¢°ë„ ì ìˆ˜
            classes = result.boxes.cls.cpu().numpy()  # í´ë˜ìŠ¤ ID

            frame_predictions = []
            for i in range(len(boxes)):
                x_min, y_min, x_max, y_max = boxes[i]

                frame_predictions.append({
                    "bbox": [float(x_min), float(y_min), float(x_max), float(y_max)],
                    "confidence": float(scores[i]),
                    "class_id": int(classes[i])
                })

            predictions.append(frame_predictions)

        print(f"ğŸ“Œ Total Predictions: {len(predictions)} Frames")
        return predictions
