import torch
import os
import numpy as np
import cv2
import io
from PIL import Image
from ts.torch_handler.base_handler import BaseHandler
from ultralytics import YOLO

class PositionHandler(BaseHandler):
    def initialize(self, context):
        """ ğŸ“Œ ëª¨ë¸ ì´ˆê¸°í™” """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model_dir = context.system_properties.get("model_dir")
        model_path = os.path.join(model_dir, "position_adjuster.pt")

        # YOLOv8 ëª¨ë¸ ë¡œë“œ
        self.model = YOLO(model_path).to(self.device)
        self.model.eval()

        print(f"âœ… Position Detection Model (YOLOv8) Loaded Successfully!")

        # ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ íŒŒë¼ë¯¸í„°
        self.calibration_matrix = np.array([
            [267.79650171, 0., 140.13033557],
            [0., 271.46411043, 147.62847192],
            [0., 0., 1.]
        ])
        self.distortion_coefficients = np.array([-0.51294983, 3.29922758, -0.01057857, -0.01969346, -6.78451324])

        # ê°ì²´ í¬ê¸° ì •ë³´ (ë‹¨ìœ„: m)
        self.object_real_size = {
            "green": (0.098, 0.098),  # ë¹„ìƒêµ¬
            "silver": (0.098, 0.136)  # ì†Œí™”ì „
        }

        # ì›”ë“œ ì¢Œí‘œ (ê°ì²´ì˜ ê³ ì •ëœ ìœ„ì¹˜)
        self.object_world_coords = {
            "green": np.array([-0.23252665996551514, -0.0031995137687772512, -0.001434326171875]),
            "silver": np.array([0.8195663690567017, 1.2595571279525757, 0.002471923828125])
        }

    def preprocess(self, data):
        """ ğŸ“Œ ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ """
        try:
            image_bytes = data[0].get("body", None)
            if image_bytes is None:
                raise ValueError("âŒ Received empty image data")

            image = np.array(Image.open(io.BytesIO(image_bytes)))

            # ì¹´ë©”ë¼ ì™œê³¡ ë³´ì •
            h, w = image.shape[:2]
            new_camera_matrix, _ = cv2.getOptimalNewCameraMatrix(
                self.calibration_matrix, self.distortion_coefficients, (w, h), 1, (w, h)
            )
            image = cv2.undistort(image, self.calibration_matrix, self.distortion_coefficients, None, new_camera_matrix)

            # Torch ë³€í™˜
            image = torch.from_numpy(image).permute(2, 0, 1).float().to(self.device) / 255.0
            return {"image": image}

        except Exception as e:
            print(f"âŒ Preprocessing error: {e}")
            return None

    def inference(self, data):
        """ ğŸ“Œ YOLOv8 ê¸°ë°˜ ê°ì²´ íƒì§€ """
        with torch.no_grad():
            results = self.model(data["image"].unsqueeze(0), verbose=False)[0]
        return results

    def postprocess(self, detection):
        """ ğŸ“Œ ìœ„ì¹˜ ë° ë°©í–¥ ë¶„ì„ """
        predictions = []
        
        if hasattr(detection, "masks") and detection.masks is not None:
            for i, mask in enumerate(detection.masks.xy):
                # numpy arrayë¥¼ ì¼ë°˜ listë¡œ ë³€í™˜
                mask = np.array(mask, dtype=np.int32).tolist()

                # í´ë˜ìŠ¤ ID ê°€ì ¸ì˜¤ê¸° (tensorë¥¼ intë¡œ ë³€í™˜)
                class_id = int(detection.boxes.cls[i].cpu().item())
                class_name = self.model.names[class_id] if class_id in self.model.names else "Unknown"

                # ë§ˆìŠ¤í¬ë¥¼ numpy arrayë¡œ ë³€í™˜ (ê³„ì‚°ìš©)
                mask_np = np.array(mask, dtype=np.int32)

                # ë§ˆìŠ¤í¬ ì¤‘ì‹¬ì  ê³„ì‚°
                M = cv2.moments(mask_np)
                if M["m00"] == 0:
                    continue
                u = int(M["m10"] / M["m00"])
                v = int(M["m01"] / M["m00"])

                # ê±°ë¦¬(Z) ê³„ì‚°
                if class_name in self.object_real_size:
                    W_real, H_real = self.object_real_size[class_name]
                    Z = float((self.calibration_matrix[1, 1] * H_real) / cv2.boundingRect(mask_np)[3])

                    # í”½ì…€ ì¢Œí‘œ â†’ ì¹´ë©”ë¼ ì¢Œí‘œ ë³€í™˜
                    pixel_coords = np.array([u, v, 1])
                    cam_coords = Z * np.linalg.inv(self.calibration_matrix) @ pixel_coords
                    X_cam, Y_cam, Z_cam = [float(x) for x in cam_coords.flatten()]

                    # ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ì›”ë“œ ì¢Œí‘œ ë³€í™˜
                    if class_name in self.object_world_coords:
                        X_obj, Y_obj, Z_obj = [float(x) for x in self.object_world_coords[class_name]]

                        # ë¡œë´‡ ìœ„ì¹˜ ë³´ì •
                        X_robot = float(X_obj - X_cam)
                        Y_robot = float(Y_obj - Y_cam)
                        Z_robot = float(Z_obj - Z_cam)

                        # ë°©í–¥ ë¶„ì„ (PCA ê¸°ë°˜)
                        mean, eigenvectors = cv2.PCACompute(mask_np.astype(np.float32), mean=None)
                        yaw_angle = float(np.arctan2(eigenvectors[0, 1], eigenvectors[0, 0]))

                        # ë°©í–¥ ê°’ ë³€í™˜
                        Z_orientation = float(np.sin(yaw_angle))
                        W_orientation = float(abs(np.cos(yaw_angle)))

                        predictions.append({
                            "class": class_name,
                            "position": {
                                "X": round(float(X_robot), 6),
                                "Y": round(float(Y_robot), 6),
                                "Z": round(float(Z_robot), 6)
                            },
                            "orientation": {
                                "Z": round(float(Z_orientation), 4),
                                "W": round(float(W_orientation), 4)
                            }
                        })

        return predictions

    def handle(self, data, context):
        """ ğŸ“Œ TorchServe ë°°ì¹˜ ì²˜ë¦¬ ëŒ€ì‘ """
        
        batch_size = len(data)  # âœ… ì…ë ¥ ë°°ì¹˜ í¬ê¸° í™•ì¸
        preprocessed_data = [self.preprocess([d]) for d in data]  # âœ… ê°œë³„ ì „ì²˜ë¦¬

        # ğŸ”¹ ì „ì²˜ë¦¬ ì‹¤íŒ¨í•œ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ìœ ì§€
        preprocessed_data = [p if p else {} for p in preprocessed_data]

        detections = [self.inference(p) for p in preprocessed_data]
        responses = [self.postprocess(d) for d in detections]

        # âœ… í•­ìƒ ì…ë ¥ ê°œìˆ˜ì™€ ë™ì¼í•œ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return responses if len(responses) == batch_size else [[]] * batch_size



